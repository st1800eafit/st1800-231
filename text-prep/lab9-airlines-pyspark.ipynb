{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configuración en google colab de spark y pyspark\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instalar java y spark\n",
    "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
    "!wget -q https://downloads.apache.org/spark/spark-3.3.2/spark-3.3.2-bin-hadoop3.tgz\n",
    "!tar xf spark-3.3.2-bin-hadoop3.tgz\n",
    "!pip install -q findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.2-bin-hadoop3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuración local de pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import monotonically_increasing_id, col, expr, when, concat, lit, isnan\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.regression import GeneralizedLinearRegression\n",
    "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression\n",
    "from pyspark.ml.feature import VectorIndexer, VectorAssembler, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, RegressionEvaluator, BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark import SparkContext\n",
    "#sc = SparkContext(\"local\", \"airlines\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.sql import SparkSession\n",
    "#spark = SparkSession.builder.appName('airlines').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+---------+--------+------+--------+-----+-----------+--------------------+\n",
      "|   id|        airline|     date|location|rating|   cabin|value|recommended|              review|\n",
      "+-----+---------------+---------+--------+------+--------+-----+-----------+--------------------+\n",
      "|10001|Delta Air Lines|21-Jun-14|Thailand|     7| Economy|    4|        YES|Flew Mar 30 NRT t...|\n",
      "|10002|Delta Air Lines|19-Jun-14|     USA|     0| Economy|    2|         NO|Flight 2463 leavi...|\n",
      "|10003|Delta Air Lines|18-Jun-14|     USA|     0| Economy|    1|         NO|Delta Website fro...|\n",
      "|10004|Delta Air Lines|17-Jun-14|     USA|     9|Business|    4|        YES|\"I just returned ...|\n",
      "|10005|Delta Air Lines|17-Jun-14| Ecuador|     7| Economy|    3|        YES|\"Round-trip fligh...|\n",
      "|10006|Delta Air Lines|17-Jun-14|     USA|     9|Business|    5|        YES|Narita - Bangkok ...|\n",
      "|10007|Delta Air Lines|14-Jun-14|      UK|     0| Economy|    1|         NO|Flight from NY La...|\n",
      "|10008|Delta Air Lines|14-Jun-14|     USA|     0| Economy|    1|         NO|Originally I had ...|\n",
      "|10009|Delta Air Lines|13-Jun-14|     USA|     4|Business|    2|         NO|We flew paid busi...|\n",
      "|10010|Delta Air Lines|13-Jun-14|      UK|     9| Economy|    3|        YES|\"I flew from Heat...|\n",
      "+-----+---------------+---------+--------+------+--------+-----+-----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#df=spark.read.csv(\"gdrive/MyDrive/st1800-231/datasets/airlines.csv\", inferSchema=True, header=True)\n",
    "df=spark.read.csv(\"../datasets/airlines.csv\", inferSchema=True, header=True)\n",
    "\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+---------+---------+------+--------+-----+-----------+--------------------+\n",
      "|   id|        airline|     date| location|rating|   cabin|value|recommended|              review|\n",
      "+-----+---------------+---------+---------+------+--------+-----+-----------+--------------------+\n",
      "|10001|Delta Air Lines|21-Jun-14| Thailand|     7| Economy|    4|        YES|Flew Mar 30 NRT t...|\n",
      "|10002|Delta Air Lines|19-Jun-14|      USA|     0| Economy|    2|         NO|Flight 2463 leavi...|\n",
      "|10003|Delta Air Lines|18-Jun-14|      USA|     0| Economy|    1|         NO|Delta Website fro...|\n",
      "|10004|Delta Air Lines|17-Jun-14|      USA|     9|Business|    4|        YES|\"I just returned ...|\n",
      "|10005|Delta Air Lines|17-Jun-14|  Ecuador|     7| Economy|    3|        YES|\"Round-trip fligh...|\n",
      "|10006|Delta Air Lines|17-Jun-14|      USA|     9|Business|    5|        YES|Narita - Bangkok ...|\n",
      "|10007|Delta Air Lines|14-Jun-14|       UK|     0| Economy|    1|         NO|Flight from NY La...|\n",
      "|10008|Delta Air Lines|14-Jun-14|      USA|     0| Economy|    1|         NO|Originally I had ...|\n",
      "|10009|Delta Air Lines|13-Jun-14|      USA|     4|Business|    2|         NO|We flew paid busi...|\n",
      "|10010|Delta Air Lines|13-Jun-14|       UK|     9| Economy|    3|        YES|\"I flew from Heat...|\n",
      "|10011|Delta Air Lines|11-Jun-14|      USA|    10| Economy|    4|        YES|I was a bit stubb...|\n",
      "|10012|Delta Air Lines|10-Jun-14|Australia|    10| Economy|    5|        YES|JFK-LHR. Had a gr...|\n",
      "|10013|Delta Air Lines| 9-Jun-14|      USA|     0| Economy|    1|         NO|My wife and I fly...|\n",
      "|10014|Delta Air Lines| 9-Jun-14|      USA|    10| Premium|    5|        YES|DL 1134 PBI-ATL. ...|\n",
      "|10015|Delta Air Lines| 6-Jun-14|      USA|     0| Economy|    2|         NO|Our flight from F...|\n",
      "|10016|Delta Air Lines| 5-Jun-14|      USA|     0| Economy|    1|         NO|On May 22 after a...|\n",
      "|10017|Delta Air Lines| 3-Jun-14|   Canada|     9| Economy|    4|        YES|Considering how D...|\n",
      "|10018|Delta Air Lines| 2-Jun-14|      USA|     9| Economy|    5|        YES|Travelled MSP-LHR...|\n",
      "|10019|Delta Air Lines|29-May-14|      USA|     7|Business|    2|        YES|JFK-LAX on a 757-...|\n",
      "|10020|Delta Air Lines|28-May-14|       UK|     9| Economy|    3|        YES|Third long haul f...|\n",
      "+-----+---------------+---------+---------+------+--------+-----+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"train_df\")\n",
    "sqlDF = spark.sql(\"SELECT * FROM train_df\")\n",
    "sqlDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import codecs\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/emontoya/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/emontoya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# stopwords en nltk\n",
    "from nltk.corpus import stopwords\n",
    " \n",
    "stop_words_nltk = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, CountVectorizer\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.linalg import Vectors, SparseVector\n",
    "from pyspark.ml.clustering import LDA, BisectingKMeans\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- cabin: string (nullable = true)\n",
      " |-- value: string (nullable = true)\n",
      " |-- recommended: string (nullable = true)\n",
      " |-- review: string (nullable = true)\n",
      "\n",
      "+-----+---------------+---------+--------+------+--------+-----+-----------+--------------------+---+----------+\n",
      "|   id|        airline|     date|location|rating|   cabin|value|recommended|              review|uid|year_month|\n",
      "+-----+---------------+---------+--------+------+--------+-----+-----------+--------------------+---+----------+\n",
      "|10001|Delta Air Lines|21-Jun-14|Thailand|     7| Economy|    4|        YES|Flew Mar 30 NRT t...|  0|    21-Jun|\n",
      "|10002|Delta Air Lines|19-Jun-14|     USA|     0| Economy|    2|         NO|Flight 2463 leavi...|  1|    19-Jun|\n",
      "|10003|Delta Air Lines|18-Jun-14|     USA|     0| Economy|    1|         NO|Delta Website fro...|  2|    18-Jun|\n",
      "|10004|Delta Air Lines|17-Jun-14|     USA|     9|Business|    4|        YES|\"I just returned ...|  3|    17-Jun|\n",
      "|10005|Delta Air Lines|17-Jun-14| Ecuador|     7| Economy|    3|        YES|\"Round-trip fligh...|  4|    17-Jun|\n",
      "|10006|Delta Air Lines|17-Jun-14|     USA|     9|Business|    5|        YES|Narita - Bangkok ...|  5|    17-Jun|\n",
      "|10007|Delta Air Lines|14-Jun-14|      UK|     0| Economy|    1|         NO|Flight from NY La...|  6|    14-Jun|\n",
      "|10008|Delta Air Lines|14-Jun-14|     USA|     0| Economy|    1|         NO|Originally I had ...|  7|    14-Jun|\n",
      "|10009|Delta Air Lines|13-Jun-14|     USA|     4|Business|    2|         NO|We flew paid busi...|  8|    13-Jun|\n",
      "|10010|Delta Air Lines|13-Jun-14|      UK|     9| Economy|    3|        YES|\"I flew from Heat...|  9|    13-Jun|\n",
      "+-----+---------------+---------+--------+------+--------+-----+-----------+--------------------+---+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "('id', 'string')\n",
      "('airline', 'string')\n",
      "('date', 'string')\n",
      "('location', 'string')\n",
      "('rating', 'string')\n",
      "('cabin', 'string')\n",
      "('value', 'string')\n",
      "('recommended', 'string')\n",
      "('review', 'string')\n",
      "('uid', 'bigint')\n",
      "('year_month', 'string')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('rating', 'int')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawdata = spark.read.load(\"../datasets/airlines.csv\", format=\"csv\", header=True)\n",
    "rawdata.printSchema()\n",
    "rawdata[0]\n",
    "rawdata = rawdata.fillna({'review': ''})                               # Replace nulls with blank string\n",
    "\n",
    "# Add Unique ID\n",
    "rawdata = rawdata.withColumn(\"uid\", monotonically_increasing_id())     # Create Unique ID\n",
    "\n",
    "# Generate YYYY-MM variable\n",
    "rawdata = rawdata.withColumn(\"year_month\", rawdata.date.substr(1,6))\n",
    "\n",
    "# Show rawdata (as DataFrame)\n",
    "rawdata.show(10)\n",
    "\n",
    "# Print data types\n",
    "for type in rawdata.dtypes:\n",
    "    print(type)\n",
    "\n",
    "target = rawdata.select(rawdata['rating'].cast(IntegerType()))\n",
    "target.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+---------+--------+------+--------+-----+-----------+--------------------+-------------------+\n",
      "|   id|        airline|     date|location|rating|   cabin|value|recommended|              review|              words|\n",
      "+-----+---------------+---------+--------+------+--------+-----+-----------+--------------------+-------------------+\n",
      "|10001|Delta Air Lines|21-Jun-14|Thailand|     7| Economy|    4|        YES|Flew Mar 30 NRT t...|[delta, air, lines]|\n",
      "|10002|Delta Air Lines|19-Jun-14|     USA|     0| Economy|    2|         NO|Flight 2463 leavi...|[delta, air, lines]|\n",
      "|10003|Delta Air Lines|18-Jun-14|     USA|     0| Economy|    1|         NO|Delta Website fro...|[delta, air, lines]|\n",
      "|10004|Delta Air Lines|17-Jun-14|     USA|     9|Business|    4|        YES|\"I just returned ...|[delta, air, lines]|\n",
      "|10005|Delta Air Lines|17-Jun-14| Ecuador|     7| Economy|    3|        YES|\"Round-trip fligh...|[delta, air, lines]|\n",
      "+-----+---------------+---------+--------+------+--------+-----+-----------+--------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################################################################################################\n",
    "#\n",
    "#   Text Pre-processing (consider using one or all of the following):\n",
    "#       - Remove common words (with stoplist)\n",
    "#       - Handle punctuation\n",
    "#       - lowcase/upcase\n",
    "#       - Stemming\n",
    "#       - Part-of-Speech Tagging (nouns, verbs, adj, etc.)\n",
    "#\n",
    "################################################################################################\n",
    "from pyspark.sql.functions import udf,struct\n",
    "#from pyspark.sql.types import StructType\n",
    "def textprep(record):\n",
    "    text  = record[1]\n",
    "    uid   = record[0]\n",
    "    tokens = text.split()\n",
    "       \n",
    "    # Custom List of Stopwords - Add your own here\n",
    "    tokens = [re.sub('[^a-zA-Z0-9]','',word) for word in tokens]                                       # Remove special characters\n",
    "    tokens = [word.lower() for word in tokens if len(word)>2 and word.lower() not in stop_words_nltk]     # Remove stopwords and words under X length\n",
    "    return tokens\n",
    "\n",
    "udf_textprep = udf(textprep , ArrayType(StringType()))\n",
    "df = df.withColumn(\"words\", udf_textprep(struct([df[x] for x in df.columns])))\n",
    "\n",
    "#tokenizer = Tokenizer(inputCol=\"description\", outputCol=\"words\")\n",
    "#wordsData = tokenizer.transform(text)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+---------+--------+------+--------+-----+-----------+--------------------+-------------------+--------------------+--------------------+\n",
      "|   id|        airline|     date|location|rating|   cabin|value|recommended|              review|              words|         rawFeatures|            features|\n",
      "+-----+---------------+---------+--------+------+--------+-----+-----------+--------------------+-------------------+--------------------+--------------------+\n",
      "|10001|Delta Air Lines|21-Jun-14|Thailand|     7| Economy|    4|        YES|Flew Mar 30 NRT t...|[delta, air, lines]|(8,[1,2,3],[1.0,1...|(8,[1,2,3],[1.387...|\n",
      "|10002|Delta Air Lines|19-Jun-14|     USA|     0| Economy|    2|         NO|Flight 2463 leavi...|[delta, air, lines]|(8,[1,2,3],[1.0,1...|(8,[1,2,3],[1.387...|\n",
      "|10003|Delta Air Lines|18-Jun-14|     USA|     0| Economy|    1|         NO|Delta Website fro...|[delta, air, lines]|(8,[1,2,3],[1.0,1...|(8,[1,2,3],[1.387...|\n",
      "|10004|Delta Air Lines|17-Jun-14|     USA|     9|Business|    4|        YES|\"I just returned ...|[delta, air, lines]|(8,[1,2,3],[1.0,1...|(8,[1,2,3],[1.387...|\n",
      "|10005|Delta Air Lines|17-Jun-14| Ecuador|     7| Economy|    3|        YES|\"Round-trip fligh...|[delta, air, lines]|(8,[1,2,3],[1.0,1...|(8,[1,2,3],[1.387...|\n",
      "|10006|Delta Air Lines|17-Jun-14|     USA|     9|Business|    5|        YES|Narita - Bangkok ...|[delta, air, lines]|(8,[1,2,3],[1.0,1...|(8,[1,2,3],[1.387...|\n",
      "|10007|Delta Air Lines|14-Jun-14|      UK|     0| Economy|    1|         NO|Flight from NY La...|[delta, air, lines]|(8,[1,2,3],[1.0,1...|(8,[1,2,3],[1.387...|\n",
      "|10008|Delta Air Lines|14-Jun-14|     USA|     0| Economy|    1|         NO|Originally I had ...|[delta, air, lines]|(8,[1,2,3],[1.0,1...|(8,[1,2,3],[1.387...|\n",
      "|10009|Delta Air Lines|13-Jun-14|     USA|     4|Business|    2|         NO|We flew paid busi...|[delta, air, lines]|(8,[1,2,3],[1.0,1...|(8,[1,2,3],[1.387...|\n",
      "|10010|Delta Air Lines|13-Jun-14|      UK|     9| Economy|    3|        YES|\"I flew from Heat...|[delta, air, lines]|(8,[1,2,3],[1.0,1...|(8,[1,2,3],[1.387...|\n",
      "+-----+---------------+---------+--------+------+--------+-----+-----------+--------------------+-------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Term Frequency Vectorization  - Option 1 (Using hashingTF): \n",
    "#hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=20)\n",
    "#featurizedData = hashingTF.transform(clean_text)\n",
    "\n",
    "# Term Frequency Vectorization  - Option 2 (CountVectorizer)    : \n",
    "cv = CountVectorizer(inputCol=\"words\", outputCol=\"rawFeatures\", vocabSize = 1000)\n",
    "cvmodel = cv.fit(df)\n",
    "featurizedData = cvmodel.transform(df)\n",
    "\n",
    "vocab = cvmodel.vocabulary\n",
    "vocab_broadcast = sc.broadcast(vocab)\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)\n",
    "rescaledData.show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
